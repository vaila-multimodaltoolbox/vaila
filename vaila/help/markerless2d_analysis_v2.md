# markerless2d_analysis_v2.py - Professional Documentation

## üìã Module Information

- **Category:** Machine Learning / Computer Vision / Biomechanics Analysis
- **File:** `vaila/markerless2d_analysis_v2.py`
- **Lines of Code:** 2,442
- **Version:** 0.3.16
- **Author:** Paulo Roberto Pereira Santiago
- **Email:** paulosantiago@usp.br
- **GitHub:** https://github.com/vaila-multimodaltoolbox/vaila
- **Creation Date:** 29 July 2024
- **Last Updated:** 27 January 2026
- **GUI Interface:** ‚úÖ Yes (Tkinter-based)
- **License:** AGPL-3.0-or-later

---

## üìñ Overview

`markerless2d_analysis_v2.py` is an advanced 2D pose estimation tool that combines state-of-the-art computer vision models (YOLOv11 and MediaPipe) to extract human pose landmarks from video sequences. This module is specifically designed for biomechanics and motion analysis applications, providing robust multi-person detection, temporal filtering, and comprehensive data export capabilities.

### What Makes This Version Special?

This is an enhanced version that addresses limitations of traditional MediaPipe-only approaches:

- **Enhanced Detection:** YOLOv11 pre-detection improves MediaPipe's accuracy in multi-person scenarios
- **Dual Processing Modes:** Choose between YOLO-only (17 keypoints) or hybrid YOLO+MediaPipe (33 landmarks)
- **Advanced Filtering:** Multiple temporal filters (Kalman, Savitzky-Golay, Median) for smooth trajectories
- **ROI Support:** Polygon-based region of interest selection for focused analysis
- **Modern API:** Uses MediaPipe Tasks API (0.10.32+) instead of deprecated solutions API
- **GPU Acceleration:** Automatic hardware detection and optimization

---

## üéØ Key Features

### 1. **Dual Processing Modes**

#### YOLO-Only Mode (`yolo_only`)
- Uses YOLOv11-pose models exclusively
- Provides 17 keypoints (COCO format)
- Faster processing, lower memory footprint
- Ideal for: Single-person scenarios, real-time applications, resource-constrained environments

#### YOLO+MediaPipe Mode (`yolo_mediapipe`)
- YOLOv11 detects persons, MediaPipe refines pose estimation
- Provides 33 landmarks (full MediaPipe format)
- Higher accuracy, better occlusion handling
- Ideal for: Multi-person scenarios, research applications, detailed biomechanical analysis

### 2. **YOLOv11-Pose Model Selection**

Five model sizes available, balancing speed and accuracy:

| Model | Size | Speed (CPU) | Speed (GPU) | Accuracy | Use Case |
|-------|------|-------------|-------------|----------|----------|
| `yolo11n-pose.pt` | ~6 MB | Fastest | Fastest | Good | Real-time, mobile |
| `yolo11s-pose.pt` | ~19 MB | Fast | Fast | Better | Balanced performance |
| `yolo11m-pose.pt` | ~52 MB | Medium | Medium | Good | Standard analysis |
| `yolo11l-pose.pt` | ~104 MB | Slow | Fast | Very Good | High-quality analysis |
| `yolo11x-pose.pt` | ~209 MB | Slowest | Fast | Best | Research, publications |

### 3. **Advanced Temporal Filtering**

#### Kalman Filter (`kalman`)
- **Purpose:** Predictive smoothing for continuous tracking
- **Algorithm:** Weighted exponential moving average (Œ±=0.95)
- **Best For:** Smooth, continuous motion tracking
- **Trade-off:** Slight latency, very smooth output

#### Savitzky-Golay Filter (`savgol`)
- **Purpose:** Polynomial smoothing preserving signal characteristics
- **Algorithm:** Local polynomial regression (window=3)
- **Best For:** Preserving motion dynamics while reducing noise
- **Trade-off:** Requires minimum 3 frames of history

#### Moving Median Filter (`median`)
- **Purpose:** Outlier removal and spike reduction
- **Algorithm:** Median of last N frames (window=5)
- **Best For:** Removing detection errors and artifacts
- **Trade-off:** Can introduce slight lag, excellent for noisy data

#### No Filter (`none`)
- **Purpose:** Raw detection output
- **Best For:** Maximum temporal resolution, post-processing analysis

### 4. **Region of Interest (ROI) Support**

#### Polygon ROI Selection
- **Interactive Selection:** Click to add points, right-click to undo, Enter to confirm
- **Flexible Shapes:** Define irregular regions (minimum 3 points)
- **Automatic Filtering:** Only processes detections within ROI
- **Use Cases:** Focus on specific body regions, exclude background, multi-person isolation

#### Bounding Box Upscaling
- **Factor Range:** 2-8x upscaling
- **Purpose:** Improve MediaPipe accuracy on small persons
- **Mechanism:** Crops YOLO-detected person, upscales crop, runs MediaPipe, maps coordinates back
- **Default:** 4x (recommended for most scenarios)

### 5. **MediaPipe Configuration**

#### Detection Parameters
- **Min Detection Confidence** (0.0-1.0): Threshold to initiate pose detection
  - Lower values: More sensitive, may detect false positives
  - Higher values: More conservative, may miss poses
  - **Recommended:** 0.1-0.5

- **Min Tracking Confidence** (0.0-1.0): Threshold to maintain pose tracking
  - Lower values: Maintains tracking through occlusions
  - Higher values: Drops tracking when confidence drops
  - **Recommended:** 0.1-0.5

#### Model Complexity
- **0 (Lite):** Fastest, lowest accuracy, ~1.5 MB model
- **1 (Full):** Balanced, good accuracy, ~7.5 MB model
- **2 (Heavy):** Slowest, highest accuracy, ~12 MB model
- **Recommended:** 2 for research, 1 for real-time

#### Segmentation
- **Enable Segmentation:** Draws person silhouette mask
- **Smooth Segmentation:** Applies temporal smoothing to mask
- **Use Cases:** Background removal, person isolation

---

## üîß Technical Architecture

### Processing Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input Video    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frame Reader   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Use YOLO?‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  YES   ‚îÇ  NO
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ YOLO    ‚îÇ ‚îÇ MediaPipe    ‚îÇ
‚îÇ Detect  ‚îÇ ‚îÇ Direct       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ Inference    ‚îÇ
     ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ             ‚îÇ
     ‚ñº             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ Filter  ‚îÇ        ‚îÇ
‚îÇ by ROI  ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
     ‚îÇ             ‚îÇ
     ‚ñº             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ Upscale ‚îÇ        ‚îÇ
‚îÇ Crop    ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
     ‚îÇ             ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Mode Check  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ             ‚îÇ
    ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ YOLO    ‚îÇ  ‚îÇ YOLO+        ‚îÇ
‚îÇ Only    ‚îÇ  ‚îÇ MediaPipe    ‚îÇ
‚îÇ (17 KP) ‚îÇ  ‚îÇ (33 LM)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ              ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Temporal     ‚îÇ
    ‚îÇ Filter       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Coordinate   ‚îÇ
    ‚îÇ Conversion   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Export CSV   ‚îÇ
    ‚îÇ & Video      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Coordinate Systems

#### Normalized Coordinates (0-1)
- **Format:** `[x_norm, y_norm, z_depth, confidence]`
- **Range:** x, y ‚àà [0, 1]
- **Use Case:** Resolution-independent analysis, machine learning
- **File:** `*_mp_norm.csv`

#### Pixel Coordinates
- **Format:** `[x_pixel, y_pixel, z_depth, confidence]`
- **Range:** x ‚àà [0, width], y ‚àà [0, height]
- **Use Case:** Direct visualization, pixel-level analysis
- **File:** `*_mp_pixel.csv`

#### *vail√°* Format
- **Format:** `frame, p1_x, p1_y, p2_x, p2_y, ..., p33_x, p33_y`
- **Use Case:** Compatibility with *vail√°* analysis tools
- **File:** `*_mp_vaila.csv`

---

## üìä Output Files

### 1. Annotated Video (`*_mp.mp4`)
- **Content:** Original video with pose landmarks overlaid
- **Visualization:**
  - Green circles: Landmark positions
  - Red lines: Skeleton connections
  - Blue bounding boxes: YOLO detections (if enabled)
  - Yellow polygon: ROI boundary (if defined)
- **Codec:** H.264 (MP4)
- **Resolution:** Same as input video

### 2. Normalized Coordinates CSV (`*_mp_norm.csv`)
- **Format:** Standard MediaPipe format
- **Columns:** `frame_index, nose_x, nose_y, nose_z, nose_conf, left_eye_inner_x, ...`
- **Total Columns:** 1 (frame) + 33 landmarks √ó 4 (x, y, z, conf) = 133 columns
- **Use Case:** Machine learning, statistical analysis, cross-resolution comparison

### 3. Pixel Coordinates CSV (`*_mp_pixel.csv`)
- **Format:** Same structure as normalized, but in pixel coordinates
- **Use Case:** Direct visualization, pixel-level measurements, integration with image processing tools

### 4. *vail√°* Format CSV (`*_mp_vaila.csv`)
- **Format:** `frame, p1_x, p1_y, p2_x, p2_y, ..., p33_x, p33_y`
- **Total Columns:** 1 (frame) + 33 points √ó 2 (x, y) = 67 columns
- **Use Case:** Compatibility with *vail√°* plotting and analysis modules

### 5. YOLO Keypoints CSV (`*_yolo_pixel.csv`)
- **Format:** Raw YOLO keypoints (only in YOLO modes)
- **Structure:** 17 keypoints √ó 3 (x, y, confidence)
- **Use Case:** Comparison with MediaPipe, YOLO-specific analysis

### 6. Configuration File (`config.toml`)
- **Content:** Complete parameter set used for processing
- **Format:** TOML (human-readable configuration)
- **Use Case:** Reproducibility, batch processing with same settings

### 7. Processing Report (`report.txt`)
- **Content:**
  - Hardware information (CPU/GPU, versions)
  - Video metadata (resolution, FPS, duration)
  - Pipeline configuration
  - Detection statistics (frames with/without pose)
  - Performance metrics (processing speed, total time)
- **Use Case:** Quality control, performance analysis, documentation

---

## üöÄ Usage Guide

### GUI Mode (Recommended)

#### Step 1: Launch the Application
```bash
# Activate vaila environment
conda activate vaila

# Run the script
python markerless2d_analysis_v2.py
```

#### Step 2: Select Input Directory
- Click "Select Input Directory"
- Choose folder containing video files (.mp4, .avi, .mov)
- Click "OK"

#### Step 3: Select Output Directory
- Click "Select Output Directory"
- Choose or create folder for results
- Click "OK"

#### Step 4: Configure Parameters
The configuration dialog appears with the following sections:

**MediaPipe Settings:**
- **Min Detection Confidence:** 0.1 (default, adjust for sensitivity)
- **Min Tracking Confidence:** 0.1 (default, adjust for tracking stability)
- **Model Complexity:** 2 (default, 0=fast, 1=balanced, 2=accurate)
- **Enable Segmentation:** True/False (draw person silhouette)
- **Smooth Segmentation:** True/False (temporal smoothing)
- **Static Image Mode:** False (use True for single images)

**YOLO Settings:**
- **Use YOLO:** True/False (enable YOLO detection)
- **YOLO Mode:** 
  - `yolo_only`: 17 keypoints from YOLO
  - `yolo_mediapipe`: 33 landmarks from MediaPipe (recommended)
- **YOLO Model:** Select from dropdown (yolo11n to yolo11x)
- **YOLO Confidence:** 0.3 (default, adjust for detection sensitivity)

**Filtering:**
- **Filter Type:** none/kalman/savgol/median
- **BBox Upscale Factor:** 4 (default, 2-8 range)

**ROI Selection:**
- Click "Select Polygon ROI" to define region of interest
- Left-click to add points, right-click to undo
- Press Enter to confirm, Esc to cancel
- Minimum 3 points required

**Configuration Management:**
- **Save Config:** Save current settings to `.toml` file
- **Load Config:** Load previously saved settings
- **Create Config:** Reset to default values
- **Help:** Open this documentation

#### Step 5: Start Processing
- Click "OK" in configuration dialog
- Processing begins automatically
- Progress is shown in terminal/console
- Results are saved to output directory

### Programmatic Usage

```python
from vaila.markerless2d_analysis_v2 import (
    process_video,
    download_or_load_yolo_model,
    get_pose_config
)
from pathlib import Path

# 1. Load YOLO model (optional)
yolo_model = download_or_load_yolo_model("yolo11x-pose.pt")

# 2. Define configuration
config = {
    # MediaPipe settings
    'min_detection_confidence': 0.5,
    'min_tracking_confidence': 0.5,
    'model_complexity': 2,
    'enable_segmentation': True,
    'smooth_segmentation': True,
    'static_image_mode': False,
    
    # YOLO settings
    'use_yolo': True,
    'yolo_mode': 'yolo_mediapipe',  # or 'yolo_only'
    'yolo_model': 'yolo11x-pose.pt',
    'yolo_conf': 0.5,
    
    # Filtering
    'filter_type': 'kalman',  # 'none', 'kalman', 'savgol', 'median'
    
    # ROI and upscaling
    'bbox_upscale_factor': 4,
    'roi_polygon_points': None,  # or list of [x, y] points
}

# 3. Process video
video_path = Path('input_video.mp4')
output_dir = Path('output_directory')

process_video(
    video_path,
    output_dir,
    config,
    yolo_model
)
```

---

## üíª System Requirements

### Minimum Requirements
- **OS:** Windows 10+, macOS 10.15+, Linux (Ubuntu 20.04+)
- **Python:** 3.12.12
- **RAM:** 4 GB (8 GB recommended)
- **Storage:** 500 MB for models + video storage
- **CPU:** Multi-core processor (4+ cores recommended)

### Recommended Requirements
- **OS:** Latest version of Windows/macOS/Linux
- **Python:** 3.12.12
- **RAM:** 16 GB or more
- **GPU:** NVIDIA GPU with CUDA support (6 GB+ VRAM)
- **Storage:** SSD with 10+ GB free space

### Python Dependencies

```txt
opencv-python>=4.8.0
mediapipe>=0.10.32
numpy>=1.24.0
pandas>=2.0.0
ultralytics>=8.0.0
torch>=2.0.0
scipy>=1.10.0
toml>=0.10.2
```

Install via:
```bash
pip install opencv-python mediapipe numpy pandas ultralytics torch scipy toml
```

Or use the vaila environment:
```bash
conda activate vaila
```

---

## üîç Performance Characteristics

### Processing Speed

| Hardware | YOLO Model | Mode | Speed (FPS) |
|----------|------------|------|-------------|
| CPU (Intel i7) | yolo11n | yolo_only | 15-25 |
| CPU (Intel i7) | yolo11n | yolo_mediapipe | 8-15 |
| CPU (Intel i7) | yolo11x | yolo_mediapipe | 3-8 |
| GPU (RTX 3060) | yolo11n | yolo_only | 60-90 |
| GPU (RTX 3060) | yolo11n | yolo_mediapipe | 40-60 |
| GPU (RTX 3060) | yolo11x | yolo_mediapipe | 25-40 |
| GPU (RTX 4090) | yolo11x | yolo_mediapipe | 60-120 |

*Note: Speed varies significantly based on video resolution, number of persons, and system configuration.*

### Memory Usage

- **YOLO Model Loading:** 200-500 MB (depending on model size)
- **MediaPipe Model:** 50-150 MB (depending on complexity)
- **Per Video Frame:** ~10-50 MB (depending on resolution)
- **Total Peak Usage:** 1-3 GB (typical), up to 8 GB for high-resolution videos

### Accuracy Metrics

- **YOLO-Only Mode:** 
  - Keypoint Accuracy: ~85-92% (depending on model)
  - Detection Rate: ~95-98%
  
- **YOLO+MediaPipe Mode:**
  - Landmark Accuracy: ~90-95%
  - Detection Rate: ~90-95%
  - Better occlusion handling than YOLO-only

---

## üéì Best Practices

### 1. Model Selection

**For Real-Time Applications:**
- Use `yolo11n-pose.pt` with `yolo_only` mode
- Set filter to `none` or `kalman`
- Reduce video resolution if needed

**For Research/Publications:**
- Use `yolo11x-pose.pt` with `yolo_mediapipe` mode
- Set filter to `savgol` or `median`
- Use model complexity 2
- Process at original resolution

**For Multi-Person Scenarios:**
- Always use `yolo_mediapipe` mode
- Set YOLO confidence to 0.3-0.5
- Use polygon ROI to isolate target person
- Consider processing persons separately

### 2. Filter Selection

**Smooth Motion (Walking, Running):**
- Use `kalman` filter
- Provides predictive smoothing
- Maintains motion dynamics

**Noisy Data (Low Light, Compression Artifacts):**
- Use `median` filter
- Excellent outlier removal
- Preserves motion characteristics

**Preserve Dynamics (Sports, Rapid Movements):**
- Use `savgol` filter
- Polynomial smoothing
- Maintains acceleration patterns

**Maximum Resolution:**
- Use `none` filter
- Apply post-processing if needed
- Best for detailed analysis

### 3. ROI Usage

**When to Use ROI:**
- Multiple persons in frame (isolate target)
- Cluttered background
- Specific body region analysis
- Reduce processing time

**ROI Selection Tips:**
- Include entire person with margin
- Avoid cutting off limbs
- Use polygon for irregular shapes
- Save ROI in config for batch processing

### 4. Upscaling Strategy

**Small Persons (< 20% of frame):**
- Use upscale factor 4-6
- Improves MediaPipe accuracy significantly
- Slight performance cost

**Medium Persons (20-50% of frame):**
- Use upscale factor 2-4
- Balanced accuracy/speed

**Large Persons (> 50% of frame):**
- Use upscale factor 1-2
- Minimal benefit, avoid unnecessary processing

### 5. Confidence Thresholds

**Detection Confidence:**
- **Low (0.1-0.3):** More detections, may include false positives
- **Medium (0.3-0.5):** Balanced (recommended)
- **High (0.5-0.8):** Conservative, may miss some poses

**Tracking Confidence:**
- **Low (0.1-0.3):** Maintains tracking through occlusions
- **Medium (0.3-0.5):** Balanced (recommended)
- **High (0.5-0.8):** Drops tracking when uncertain

---

## üêõ Troubleshooting

### Common Issues and Solutions

#### 1. **YOLO Model Not Loading**

**Symptoms:**
- Error: "Failed to load YOLO model"
- Model download fails

**Solutions:**
- Check internet connection (first-time download required)
- Verify disk space (models are 6-209 MB)
- Manually download model to `vaila/models/` directory
- Check Ultralytics version: `pip install --upgrade ultralytics`

#### 2. **GPU Not Detected**

**Symptoms:**
- Processing is slow
- Console shows "No GPU detected"

**Solutions:**
- Install CUDA-enabled PyTorch:
  ```bash
  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
  ```
- Verify CUDA installation: `python -c "import torch; print(torch.cuda.is_available())"`
- Check GPU drivers are up to date
- Script automatically falls back to CPU if GPU unavailable

#### 3. **Memory Errors**

**Symptoms:**
- "Out of Memory" errors
- System becomes unresponsive

**Solutions:**
- Use smaller YOLO model (yolo11n or yolo11s)
- Reduce video resolution before processing
- Process videos individually instead of batch
- Close other applications
- Increase system RAM if possible

#### 4. **Poor Detection Quality**

**Symptoms:**
- Many frames without pose
- Incorrect landmark positions
- Jittery tracking

**Solutions:**
- Lower detection confidence (0.1-0.3)
- Use larger YOLO model (yolo11x)
- Increase upscale factor (4-6)
- Use `yolo_mediapipe` mode instead of `yolo_only`
- Check video quality (resolution, lighting, compression)
- Define ROI to focus on target person

#### 5. **MediaPipe Tasks API Errors**

**Symptoms:**
- "MediaPipe model not found"
- "Tasks API error"

**Solutions:**
- Update MediaPipe: `pip install --upgrade mediapipe>=0.10.32`
- Verify model files in `vaila/models/` directory
- Check MediaPipe version: `python -c "import mediapipe as mp; print(mp.__version__)"`
- Reinstall MediaPipe if issues persist

#### 6. **CSV Export Issues**

**Symptoms:**
- Missing columns in CSV
- Incorrect coordinate values
- File not created

**Solutions:**
- Check write permissions on output directory
- Verify sufficient disk space
- Ensure video was processed successfully (check report.txt)
- Check for NaN values (normal for occluded landmarks)

#### 7. **Video Export Fails**

**Symptoms:**
- Annotated video not created
- Codec errors

**Solutions:**
- Check OpenCV codec support: `python -c "import cv2; print(cv2.getBuildInformation())"`
- Verify output directory permissions
- Try different output format (if supported)
- Check available disk space

---

## üìö Technical References

### MediaPipe Pose Landmarks (33 points)

**Face (0-10):**
- 0: Nose
- 1-2: Left eye (inner, outer)
- 3-4: Right eye (inner, outer)
- 5-6: Left/Right ear
- 7-8: Mouth corners

**Upper Body (11-22):**
- 11-12: Left/Right shoulder
- 13-14: Left/Right elbow
- 15-16: Left/Right wrist
- 17-22: Hand landmarks (pinky, index, thumb)

**Lower Body (23-32):**
- 23-24: Left/Right hip
- 25-26: Left/Right knee
- 27-28: Left/Right ankle
- 29-30: Left/Right heel
- 31-32: Left/Right foot index

### YOLO11-Pose Keypoints (17 points)

**Mapping to MediaPipe:**
- 0 (nose) ‚Üí 0
- 1 (left_eye) ‚Üí 2
- 2 (right_eye) ‚Üí 5
- 3 (left_ear) ‚Üí 7
- 4 (right_ear) ‚Üí 8
- 5 (left_shoulder) ‚Üí 11
- 6 (right_shoulder) ‚Üí 12
- 7 (left_elbow) ‚Üí 13
- 8 (right_elbow) ‚Üí 14
- 9 (left_wrist) ‚Üí 15
- 10 (right_wrist) ‚Üí 16
- 11 (left_hip) ‚Üí 23
- 12 (right_hip) ‚Üí 24
- 13 (left_knee) ‚Üí 25
- 14 (right_knee) ‚Üí 26
- 15 (left_ankle) ‚Üí 27
- 16 (right_ankle) ‚Üí 28

### Temporal Filter Algorithms

**Kalman Filter:**
- Implementation: Exponential weighted moving average
- Formula: `filtered = Œ± √ó current + (1-Œ±) √ó previous`
- Œ± = 0.95 (current value weight)
- History: Last frame only

**Savitzky-Golay Filter:**
- Implementation: Local polynomial regression
- Window: 3 frames (minimum)
- Polynomial order: 2
- Preserves: Signal derivatives (velocity, acceleration)

**Moving Median Filter:**
- Implementation: Median of last N frames
- Window: 5 frames
- Removes: Outliers, spikes, detection errors
- Preserves: Step changes, motion discontinuities

---

## üîó Integration with *vail√°* ecosystem

### Compatible Modules

1. **3D Reconstruction** (`markerless3d_analysis_v2.py`)
   - Input: Pixel coordinates CSV
   - Process: DLT calibration, triangulation
   - Output: 3D pose coordinates

2. **Visualization** (`vailaplot2d.py`, `vailaplot3d.py`)
   - Input: Normalized or pixel coordinates
   - Process: Plot trajectories, angles, velocities
   - Output: Publication-quality figures

3. **Biomechanical Analysis**
   - Input: Coordinate data
   - Process: Joint angles, segment lengths, velocities
   - Output: Biomechanical parameters

4. **Data Processing** (`data_processing.py`)
   - Input: CSV files
   - Process: Filtering, interpolation, statistics
   - Output: Processed datasets

---

## üìù Version History

### v0.3.16 (January 2026)
- **Major Update:** Migrated to MediaPipe Tasks API (0.10.32+)
- **New Feature:** Manual OpenCV drawing (compatible with new MediaPipe)
- **New Feature:** Automatic model download for MediaPipe and YOLO
- **New Feature:** Polygon ROI definition
- **New Feature:** Bounding box upscale factor for improved accuracy
- **Improvement:** Better error handling and user feedback
- **Fix:** Resolved compatibility issues with MediaPipe 0.10.32+

### v0.0.2 (November 2025)
- Added YOLO-only mode
- Added YOLO11-pose model selection
- Enhanced terminal feedback
- Fixed NaN handling in filters
- Custom drawing for YOLO landmarks

### v0.0.1 (July 2024)
- Initial release with YOLO+MediaPipe integration
- Basic temporal filtering
- CSV export functionality

---

## üìû Support and Contributions

### Getting Help
- **GitHub Issues:** https://github.com/vaila-multimodaltoolbox/vaila/issues
- **Email:** paulosantiago@usp.br
- **Documentation:** See `vaila/help/` directory

### Contributing
Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request with detailed description

### Citation
If you use this module in your research, please cite:

```bibtex
@software{vaila_markerless2d_v2,
  title = {vail√° Markerless 2D Analysis v2},
  author = {Santiago, Paulo Roberto Pereira},
  year = {2026},
  version = {0.3.16},
  url = {https://github.com/vaila-multimodaltoolbox/vaila}
}
```

---

## üìÑ License

This project is licensed under the **AGPL-3.0-or-later** License.

See the [LICENSE](https://github.com/vaila-multimodaltoolbox/vaila/blob/main/LICENSE) file for details.

---

**üìÖ Last Updated:** January 27, 2026  
**üîó Part of vail√° - Multimodal Toolbox for Biomechanics and Motion Analysis**  
**üåê [GitHub Repository](https://github.com/vaila-multimodaltoolbox/vaila)**
