# _vailÃ¡_ - Multimodal Toolbox

[![GitHub release](https://img.shields.io/github/v/release/vaila-multimodaltoolbox/vaila)](https://github.com/vaila-multimodaltoolbox/vaila/releases)
[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0.html)
[![Python 3.12](https://img.shields.io/badge/python-3.12%20%7C%20uv-brightgreen)](https://github.com/astral-sh/uv)

<p align="center">
  <img src="docs/images/vaila.png" alt="vailÃ¡ Logo" width="300"/>
</p>

<div align="center">
  <table>
    <tr>
      <th>Operating System</th>
      <th>Installation Method</th>
      <th>Status</th>
    </tr>
    <tr>
      <td><strong>ğŸªŸ Windows</strong></td>
      <td>uv (Recommended)</td>
      <td>âœ… Ready</td>
    </tr>
    <tr>
      <td><strong>ğŸ§ Linux</strong></td>
      <td>uv (Recommended)</td>
      <td>âœ… Ready</td>
    </tr>
    <tr>
      <td><strong>ğŸ macOS</strong></td>
      <td>uv (Recommended)</td>
      <td>âœ… Ready</td>
    </tr>
  </table>
</div>

---

## TL;DR

**_vailÃ¡_** is an openâ€‘source Python toolbox that integrates video, motionâ€‘capture, forceâ€‘plate, IMU, EMG/EEG and GNSS data into a reproducible, endâ€‘toâ€‘end multimodal biomechanics workflow. 

**Quick Start:**
1. Install via binaries (Windows/macOS) or source code (all platforms)
2. Launch GUI: `uv run vaila.py`
3. Access all tools through the intuitive graphical interface

Installation is automated via `uv` - no manual Python setup required!

---

## Table of Contents

- [Abstract](#abstract)
- [Protocol Overview](#protocol-overview)
- [Key Features](#key-features)
- [Intended Audience](#intended-audience)
- [Installation](#stage-i-installation-and-environment-setup)
- [Quickâ€‘Start Example](#quick-start-example)
- [How to Use _vailÃ¡_](#how-to-use-vailÃ¡)
- [Workflow Details (Stages IIâ€‘VI)](#protocol-workflow-details)
- [Supported Modalities](#supported-modalities)
- [Specialized Analysis Types](#specialized-analysis-types)
- [System Requirements](#system-requirements)
- [Manifest](#vailÃ¡-manifest)
- [Project Structure](#project-structure)
- [Uninstallation](#uninstallation-instructions)
- [Citation](#citing-vailÃ¡)
- [Contributing](#contribution)
- [License](#license)
- [References](#references)

---

## Abstract

Quantitative analysis of human movement increasingly relies on integrating heterogeneous data streamsâ€”video, motion capture, force plates, inertial sensors and electrophysiological recordingsâ€”into temporally aligned, threeâ€‘dimensional representations. However, many existing tools target a single modality, require extensive adâ€‘hoc scripting or depend on proprietary software, which limits accessibility and reproducibility. Here we present **_vailÃ¡_**, an openâ€‘source Python toolbox that provides an endâ€‘toâ€‘end workflow for multimodal biomechanics. The protocol guides users through six stages: (I) installation and environment setup using the highâ€‘performance `uv` package manager; (II) video preprocessing, including synchronization and optional distortion correction; (III) markerless 2D pose estimation via MediaPipe; (IV) camera calibration with Direct Linear Transformation (DLT); (V) 3D reconstruction from multiâ€‘camera views; and (VI) interactive visualization and export to standard formats (C3D, CSV). In contrast to tools that focus solely on pose estimation or downstream musculoskeletal simulation, _vailÃ¡_ combines pose extraction, temporal synchronization, 2Dâ€‘3D reconstruction and humanâ€‘inâ€‘theâ€‘loop verification within a single, reproducible environment. The complete workflowâ€”from raw video to 3D coordinatesâ€”can be executed in approximately 1â€“4 h, depending on dataset size and hardware, and requires only basic familiarity with the command line. Example datasets, configuration files and troubleshooting guides are provided. _vailÃ¡_ enables researchers in clinical rehabilitation, sports science and motor control to perform scalable, transparent and reproducible multimodal analyses without reliance on commercial software.

---

## Protocol Overview

This software implements a standardized protocol for multimodal analysis, organized into six specific stages:

1. **Stage I: Installation & Setup** â€“ Environment creation using `uv` for reproducible Python dependency management.
2. **Stage II: Video Preprocessing** â€“ Synchronization, cutting, and distortion correction of raw video feeds.
3. **Stage III: 2D Pose Estimation** â€“ Markerless tracking using MediaPipe and YOLO models.
4. **Stage IV: Calibration** â€“ Camera parameter estimation using Direct Linear Transformation (DLT).
5. **Stage V: 3D Reconstruction** â€“ Converting 2D views into 3D metric coordinates.
6. **Stage VI: Visualization & Export** â€“ Humanâ€‘inâ€‘theâ€‘loop verification and export to C3D/CSV.

---

## Key Features

- **Multimodal integration** â€“ Video, MoCap (C3D), IMU, EMG/EEG, GNSS/GPS, force plates, HR/ECG, ultrasound.
- **Endâ€‘toâ€‘end pipeline** â€“ Six clearly defined stages from raw data to export.
- **Reproducible environment** â€“ Managed by `uv` (deterministic lockfile).
- **Dual installation tracks** â€“ Binary quickâ€‘start for nonâ€‘technical users; sourceâ€‘code protocol for reproducibility.
- **DeepLabCut integration** â€“ Import DLC pose estimation data via `dlc2vaila.py`.
- **YOLOv11 tracking** â€“ Advanced object tracking with reâ€‘identification.
- **Video processing suite** â€“ Compression (H.264/H.265/H.266), merging, resizing, frame extraction.
- **Specialized biomechanical analyses** â€“ Sitâ€‘toâ€‘Stand, vertical jump, gait (GRF), balance (stabilogram).
- **Animal behavior analysis** â€“ Open field tracking and trajectory analysis.
- **Openâ€‘source & extensible** â€“ AGPLâ€‘v3 license, community contributions welcome.
- **Extensive documentation** â€“ GUI button guide, API reference, example datasets.

---

## Intended Audience

This protocol is intended for biomechanics researchers, rehabilitation scientists, and motorâ€‘control specialists who seek an openâ€‘source, accessible, reproducible workflow for multimodal data integration without reliance on commercial platforms. 

**User Requirements:**
- Basic familiarity with command line (for installation)
- GUI-based workflow means minimal technical expertise needed for daily use
- Python knowledge helpful but not required (all tools accessible via GUI)

---

## Stage I: Installation and Environment Setup

To ensure reproducibility across different operating systems, _vailÃ¡_ offers two installation tracks:

### Option A: Quick Start (Binaries)

Preâ€‘compiled binaries are available for Windows and macOS. This is the fastest way to get started and requires no technical setup.

- **Windows**: Download `vaila-setup.exe` from the [Releases Page](https://github.com/vaila-multimodaltoolbox/vaila/releases) and run the installer.
- **macOS**: Download `vaila.dmg` from the [Releases Page](https://github.com/vaila-multimodaltoolbox/vaila/releases), mount it, and drag the application to your Applications folder.
- **Linux**: Please use the Source Code method (Option B).

After installation, launch _vailÃ¡_ from your applications menu or desktop shortcut.

### Option B: Protocol Implementation (Source Code)

This method ensures you have the exact environment used in the protocol, managed by `uv`. It allows code inspection and modification. The installation scripts automatically handle all dependencies.

#### Prerequisite: Get the Code

```bash
git clone https://github.com/vaila-multimodaltoolbox/vaila.git
cd vaila
```

#### ğŸªŸ Windows (PowerShell)

Run the installation script (Administrator privileges recommended for full installation):

```powershell
.\install_vaila_win_uv.ps1
```

**What happens during installation:**
- `uv` package manager is automatically installed if not present
- Python 3.12.12 is installed via `uv` if needed
- All Python dependencies are installed from `pyproject.toml`
- FFmpeg is installed for video processing
- Installation location:
  - **With Administrator**: `C:\Program Files\vaila`
  - **Without Administrator**: `C:\Users\<YourUser>\vaila`

#### ğŸ§ Linux (Bash)

Make the script executable and run it:

```bash
chmod +x install_vaila_linux_uv.sh
./install_vaila_linux_uv.sh
```

**What happens during installation:**
- System dependencies (Python, Git, FFmpeg, etc.) are installed via `apt`
- `uv` package manager is automatically installed if not present
- Python 3.12.12 is installed via `uv` if needed
- All Python dependencies are installed from `pyproject.toml`
- Installation location: `~/vaila`

#### ğŸ macOS (Bash/Zsh)

Make the script executable and run it:

```bash
chmod +x install_vaila_mac_uv.sh
./install_vaila_mac_uv.sh
```

**What happens during installation:**
- System dependencies are verified and installed via Homebrew if needed
- `uv` package manager is automatically installed if not present
- Python 3.12.12 is installed via `uv` if needed
- All Python dependencies are installed from `pyproject.toml`
- FFmpeg is installed for video processing
- Installation location: `~/vaila`

#### Verification

After installation, verify that _vailÃ¡_ is working correctly:

```bash
uv run vaila.py
```

If the GUI launches successfully, installation is complete!

---

## Quickâ€‘Start Example

After installation, launch the _vailÃ¡_ graphical interface:

```bash
uv run vaila.py
```

This opens the main GUI where you can access all tools through organized buttons:

- **File Management (Frame A)**: Rename, import, export, copy, move, and organize files
- **Multimodal Analysis (Frame B)**: IMU, MoCap, markerless tracking, EMG, force plates, and more
- **Tools (Frame C)**: Video processing, DLT calibration, data conversion, visualization

The GUI provides an intuitive way to access all _vailÃ¡_ functionality without command-line complexity.

### Running Individual Modules

You can also run individual modules directly from the command line:

```bash
# Run YOLOv11 tracker
uv run python -m vaila.yolov11track

# Run markerless 2D analysis
uv run python -m vaila.markerless_2d_analysis

# Run video cutting tool
uv run python -m vaila.cutvideo
```

All modules are accessible both through the GUI and directly via command line.

---

## How to Use _vailÃ¡_

_vailÃ¡_ is primarily a GUI-based application, making it accessible to users with minimal command-line experience.

### Launching the Application

**Main GUI (Recommended):**
```bash
uv run vaila.py
```

This launches the main graphical interface where all tools are organized into logical sections. Most users will interact with _vailÃ¡_ exclusively through this GUI.

### Accessing Tools

**Via GUI:**
- Click buttons in the main interface to launch specific tools
- Each tool opens its own configuration dialog
- Follow on-screen prompts to select files and configure parameters

**Via Command Line (Advanced):**
Individual modules can be run directly for scripting and automation:
```bash
uv run python -m vaila.<module_name>
```

### Documentation

- **GUI Button Guide**: See `docs/vaila_buttons/README.md` for detailed documentation on all GUI buttons
- **Module Help**: Each module includes built-in help accessible via the GUI
- **Online Documentation**: Visit the [project documentation](docs/index.md) for comprehensive guides

---

## Protocol Workflow Details

The integration of _vailÃ¡_ into your research pipeline follows these processing stages. All tools are accessible through the GUI, and can also be run directly as Python modules:

### Stage II: Video Preprocessing

- **Goal**: Prepare video data for analysis to ensure temporal and spatial alignment.
- **Access**: GUI buttons in Frame C (Video and Image tools) or run modules directly
- **Core Tools**:
  - **Synchronization**: `syncvid.py` (`C_B_r2_c3`) â€“ Multiâ€‘camera temporal alignment with flash detection
  - **Trimming**: `cutvideo.py` (`C_B_r4_c2`) â€“ Interactive frameâ€‘accurate cutting with batch support
  - **Lens Correction**: `vaila_distortvideo_gui.py` (`C_B_r4_c1`) â€“ Radial distortion removal
- **Additional Tools**:
  - **Compression**: `compress_videos_h264.py`, `compress_videos_h265.py`, `compress_videos_h266.py` (`C_B_r2_c1`, `C_B_r2_c2`)
  - **Frame Extraction**: `extractpng.py` (`C_B_r1_c1`) â€“ Export frames as PNG sequences
  - **Video Merging**: `merge_multivideos.py` (`C_B_r3_c3`) â€“ Combine multiple video sources
  - **Resizing**: `resize_video.py` (`C_B_r4_c3`) â€“ Change resolution while preserving aspect ratio
  - **Metadata**: `numberframes.py` (`C_B_r3_c2`) â€“ Extract precise video metadata (FPS, duration, frame count)
  - **Duplicate Removal**: `rm_duplicateframes.py` â€“ Clean repeated frames

### Stage III: Markerless 2D Pose Estimation

- **Goal**: Extract biological landmark coordinates from standard 2D video feeds.
- **Access**: GUI buttons in Frame B (Multimodal Analysis) or run modules directly
- **Core Tools**:
  - **MediaPipe + YOLO**: `markerless2d_mpyolo.py` (`B3_r3_c2`) â€“ Combined detection and pose estimation
  - **MediaPipe Standalone**: `markerless_2d_analysis.py` (`B1_r1_c4`) â€“ Fullâ€‘body pose (33 landmarks) with CPU/GPU options
  - **Hand Tracking**: `mphands.py` (`B3_r4_c3`) â€“ 21 hand landmarks per hand
- **Additional Tools**:
  - **DeepLabCut Import**: `dlc2vaila.py` â€“ Convert DLC outputs to vailÃ¡ format
  - **YOLOv11 Tracking**: `yolov11track.py` (`B3_r4_c1`) â€“ Multi-object tracking with reâ€‘identification (BoT-SORT/ByteTrack)
  - **Angle Calculation**: `mpangles.py` (`B3_r4_c4`) â€“ Joint angles from MediaPipe landmarks
  - **Live Tracking**: `markerless_live.py` (`B3_r4_c5`) â€“ Real-time pose estimation from webcam

### Stage IV: Camera Calibration (DLT)

- **Goal**: Establish the mathematical relationship between 2D pixel space and 3D metric space.
- **Access**: GUI buttons in Frame C (Data Files tools) or run modules directly
- **Tools**:
  - **2D Calibration**: `dlt2d.py` (`C_A_r2_c1`) â€“ 8â€‘parameter DLT for planar analysis
  - **3D Calibration**: `dlt3d.py` (`C_A_r3_c1`) â€“ 11â€‘parameter DLT for volumetric reconstruction
  - **Camera Parameters**: `getcampardistortlens.py` â€“ Extract intrinsic parameters

### Stage V: 3D Reconstruction

- **Goal**: Triangulate 2D coordinates from multiple views into a unified 3D reconstruction.
- **Access**: GUI buttons in Frame C (Data Files tools) or run modules directly
- **Tools**:
  - **Multiâ€‘Camera Reconstruction**: `rec3d.py` (`C_A_r3_c2`) â€“ Leastâ€‘squares triangulation
  - **Singleâ€‘DLT 2D Reconstruction**: `rec2d_one_dlt2d.py` (`C_A_r2_c2`) â€“ Planar reconstruction
  - **Multiâ€‘DLT 3D Reconstruction**: `rec3d_one_dlt3d.py` (`C_A_r3_c3`) â€“ Perâ€‘frame DLT parameters

### Stage VI: Visualization and Export

- **Goal**: Validate results through visualization and export standard biomechanics formats.
- **Access**: GUI buttons in Frame C (Visualization tools) or run modules directly
- **Core Tools**:
  - **3D Viewer**: `viewc3d.py` (`C_C_r2_c2`) â€“ Interactive Open3D visualization with marker selection
  - **2D Plotting**: `vailaplot2d.py` (`C_C_r2_c1`) â€“ Time series, scatter, and multiâ€‘axis plots
  - **C3D Preview**: `showc3d.py` (`C_C_r1_c1`) â€“ Quick C3D file inspection
  - **CSV Viewer**: `readcsv.py` (`C_C_r1_c2`) â€“ Browse and inspect CSV data
- **Export Formats**:
  - **C3D**: Standard motion capture format (Vicon, Qualisys compatible)
  - **CSV**: Universal tabular format for statistical analysis
  - **Excel**: Optional `.xlsx` export for spreadsheet users

---

## Supported Modalities

| Modality            | Input Formats      | Key Scripts                                 | Description                          |
| ------------------- | ------------------ | ------------------------------------------- | ------------------------------------ |
| **Motion Capture**  | C3D, CSV           | `readc3d_export.py`, `mocap_analysis.py`    | Vicon, Qualisys, OptiTrack           |
| **Markerless Pose** | Video (MP4, AVI)   | `markerless2d_mpyolo.py`                    | MediaPipe, YOLO, DeepLabCut          |
| **IMU/Inertial**    | CSV, C3D           | `imu_analysis.py`                           | Delsys, Noraxon, Xsens               |
| **EMG**             | CSV, C3D           | `emg_labiocom.py`                           | Spectral analysis, fatigue detection |
| **Force Plates**    | CSV, C3D           | `forceplate_analysis.py`, `cop_analysis.py` | AMTI, Bertec, Kistler                |
| **GNSS/GPS**        | GPX, KML, KMZ, CSV | `gnss_analysis.py`                          | Trajectory, speed, distance          |
| **Ultrasound**      | Images             | `usound_biomec1.py`                         | Muscle architecture analysis         |

---

## Specialized Analysis Types

| Analysis                  | Script                                       | Description                                            |
| ------------------------- | -------------------------------------------- | ------------------------------------------------------ |
| **Balance/Posturography** | `cop_analysis.py`, `stabilogram_analysis.py` | Center of Pressure, sway metrics, ellipse area         |
| **Gait Analysis**         | `grf_gait.py`, `numstepsmp.py`               | Ground reaction forces, step detection, spatiotemporal |
| **Vertical Jump**         | `vaila_and_jump.py`                          | Countermovement jump metrics (flight time, peak force) |
| **Sitâ€‘toâ€‘Stand**          | `sit2stand.py`                               | Functional mobility assessment                         |
| **Vector Coding**         | `run_vector_coding.py`                       | Intersegmental coordination patterns                   |
| **Cluster Kinematics**    | `cluster_analysis.py`                        | Euler angles from marker clusters                      |
| **Animal Open Field**     | `animal_open_field.py`                       | Rodent trajectory and behavior analysis                |
| **Soccer Field**          | `soccerfield.py`                             | Player tracking visualization                          |

---

## System Requirements

- **Operating Systems**: Windows 10 or later, macOS 12 or later, Ubuntu 20.04 or later
- **Python**: 3.12.12 (automatically installed by `uv` during installation - no manual Python setup required)
- **Package Manager**: `uv` (automatically installed by installation scripts if not present)
- **External Dependencies**:
  - **FFmpeg**: Automatically installed by installation scripts (required for video processing)
  - **CUDA**: Optional, for GPUâ€‘accelerated YOLO and MediaPipe processing (NVIDIA GPUs only)
  - **Git**: Required for cloning the repository (usually pre-installed)
- **Hardware**:
  - **Minimum**: 8 GB RAM
  - **Recommended**: 16+ GB RAM, NVIDIA GPU with CUDA support for faster processing of large video datasets

---

## _vailÃ¡_ Manifest

### English Version

Join us in the liberation from paid software with the "_vailÃ¡_ â€“ Versatile Anarcho Integrated Liberation Ãnalysis in Multimodal Toolbox."

In front of you stands a versatile tool designed to challenge the boundaries of commercial systems. This software is a symbol of innovation and freedom, determined to eliminate barriers that protect the monopoly of expensive software, ensuring the dissemination of knowledge and accessibility.

With _vailÃ¡_ you are invited to explore, experiment, and create without constraints. "_vailÃ¡_" means "go there and do it!" â€” encouraging you to harness its power to perform analysis with data from multiple systems.

### VersÃ£o em PortuguÃªs

Junte-se a nÃ³s na libertaÃ§Ã£o do software pago com o "_vailÃ¡_: AnÃ¡lise VersÃ¡til da LibertaÃ§Ã£o Anarquista Integrada na Caixa de Ferramentas Multimodal".

Diante de vocÃª estÃ¡ uma ferramenta versÃ¡til, projetada para desafiar as fronteiras dos sistemas comerciais. Este software Ã© um sÃ­mbolo de inovaÃ§Ã£o e liberdade, determinado a eliminar as barreiras que protegem o monopÃ³lio do software caro, garantindo a disseminaÃ§Ã£o do conhecimento e a acessibilidade.

Com _vailÃ¡_ vocÃª Ã© convidado a explorar, experimentar e criar sem restriÃ§Ãµes. "_vailÃ¡_" significa "vai lÃ¡ e faÃ§a!" â€” encorajando vocÃª a aproveitar seu poder para realizar anÃ¡lises com dados de mÃºltiplos sistemas.

---

## Project Structure

```text
vaila/
â”œâ”€â”€ vaila.py                    # Main entry point (GUI launcher)
â”œâ”€â”€ pyproject.toml              # Dependency specification (uv)
â”œâ”€â”€ uv.lock                     # Locked dependency versions (uv)
â”‚
â”œâ”€â”€ install_vaila_win_uv.ps1    # Windows installation script (uv)
â”œâ”€â”€ install_vaila_linux_uv.sh   # Linux installation script (uv)
â”œâ”€â”€ install_vaila_mac_uv.sh     # macOS installation script (uv)
â”‚
â”œâ”€â”€ vaila/                      # Main package directory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ markerless_2d_analysis.py      # MediaPipe 2D pose (CPU/GPU)
â”‚   â”œâ”€â”€ markerless_2d_analysis_nvidia.py  # MediaPipe GPU acceleration
â”‚   â”œâ”€â”€ markerless2d_mpyolo.py         # MediaPipe + YOLO combined
â”‚   â”œâ”€â”€ yolov11track.py                # YOLOv11 multi-object tracking
â”‚   â”œâ”€â”€ cutvideo.py                    # Video cutting tool
â”‚   â”œâ”€â”€ numberframes.py               # Video metadata extraction
â”‚   â”œâ”€â”€ syncvid.py                    # Video synchronization
â”‚   â”œâ”€â”€ dlt2d.py, dlt3d.py            # DLT calibration
â”‚   â”œâ”€â”€ rec2d.py, rec3d.py            # 2D/3D reconstruction
â”‚   â”œâ”€â”€ viewc3d.py                    # 3D visualization
â”‚   â”œâ”€â”€ imu_analysis.py               # IMU data analysis
â”‚   â”œâ”€â”€ mocap_analysis.py             # Motion capture analysis
â”‚   â”œâ”€â”€ forceplate_analysis.py        # Force plate analysis
â”‚   â”œâ”€â”€ emg_labiocom.py               # EMG analysis
â”‚   â”œâ”€â”€ models/                       # Trained models (YOLO, MediaPipe, etc.)
â”‚   â”œâ”€â”€ help/                         # Module help documentation (HTML/MD)
â”‚   â”‚   â”œâ”€â”€ index.html, index.md
â”‚   â”‚   â”œâ”€â”€ analysis/                 # Analysis tool documentation
â”‚   â”‚   â”œâ”€â”€ tools/                    # Utility tool documentation
â”‚   â”‚   â””â”€â”€ ml/                       # Machine learning documentation
â”‚   â””â”€â”€ ... (100+ additional modules)
â”‚
â”œâ”€â”€ docs/                       # Project documentation
â”‚   â”œâ”€â”€ index.md                 # Main documentation index
â”‚   â”œâ”€â”€ help.md                  # User help guide
â”‚   â”œâ”€â”€ images/                  # Documentation images
â”‚   â”œâ”€â”€ vaila_buttons/           # GUI button documentation
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ tools/                # Tool button docs
â”‚   â”‚   â”œâ”€â”€ ml-walkway/           # ML walkway docs
â”‚   â”‚   â””â”€â”€ ... (button-specific docs)
â”‚   â””â”€â”€ api/                     # API reference documentation
â”‚
â””â”€â”€ tests/                      # Test suite with example data
    â”œâ”€â”€ markerless_2d_analysis/  # Test videos and configs
    â”œâ”€â”€ DLT3D_and_Rec3d/         # DLT test data
    â”œâ”€â”€ C3D_to_CSV_TOOLS/        # C3D conversion tests
    â””â”€â”€ ... (additional test data)
```

**Key Directories:**
- **`vaila/`**: All Python modules and scripts
- **`vaila/help/`**: Built-in help documentation for each module (HTML and Markdown)
- **`docs/`**: Project-wide documentation, GUI button guides, and API reference
- **`tests/`**: Example datasets and test files for various modules

---

## Uninstallation Instructions

### Linux

```bash
sudo chmod +x uninstall_vaila_linux.sh
./uninstall_vaila_linux.sh
```

### macOS

```bash
sudo chmod +x uninstall_vaila_mac.sh
./uninstall_vaila_mac.sh
```

### Windows (uv method)

**With Administrator privileges:**
- Delete the installation folder: `C:\Program Files\vaila`
- Remove desktop shortcuts and Start Menu entries
- Remove Windows Terminal profile if created

**Without Administrator privileges:**
- Delete the installation folder: `C:\Users\<YourUser>\vaila`
- Remove desktop shortcuts if created

**Note:** The `uv` environment and Python installation remain on your system. To completely remove Python installed by `uv`, you may need to manually delete `%LOCALAPPDATA%\uv` (advanced users only).

---

## Citing _vailÃ¡_

```bibtex
@misc{vaila2024,
  title={vailÃ¡ â€“ Versatile Anarcho Integrated Liberation Ãnalysis in Multimodal Toolbox},
  author={Paulo Roberto Pereira Santiago and Guilherme Manna Cesar and Ligia Yumi Mochida and Juan Aceros and others},
  year={2024},
  eprint={2410.07238},
  archivePrefix={arXiv},
  primaryClass={cs.HC},
  url={https://arxiv.org/abs/2410.07238}
}

@article{santiago2025vaila,
  title={vailÃ¡: an openâ€‘source multimodal toolbox for biomechanics},
  author={Santiago, Paulo RP and Cesar, Guilherme M and Mochida, Ligia Y and others},
  journal={Nature Protocols},
  year={2025},
  doi={10.1038/s41596-025-XXXX-X}
}
```

Please cite both the preâ€‘print and the final Nature Protocols article.

---

## Contribution

We encourage creativity and innovation to enhance and expand the functionality of this toolbox. Fork the repository, experiment with new ideas, and create a branch for your changes. When you're ready, submit a pull request so we can review and potentially integrate your contributions.

---

## License

This project is licensed under the GNU Affero General Public License v3.0 (AGPLâ€‘v3). The license ensures that any use of _vailÃ¡_, including network/server usage, maintains the freedom of the software and requires sourceâ€‘code availability.

---

## References

1. Santiago, P. R. P. _et al._ "vailÃ¡ â€“ Versatile Anarcho Integrated Liberation Ãnalysis in Multimodal Toolbox". _arXiv_ 2410.07238 (2024).
2. Tahara, A. K., Chinaglia, A. G., Monteiro, R. L. M., et al. "Predicting walkway spatiotemporal parameters using a markerless, pixelâ€‘based machine learning approach". _Brazilian Journal of Motor Behavior_ 19, 1 (2025).
3. Mochida, L. Y., Santiago, P. R. P., Lamb, M., Cesar, G. M. "Multimodal Motion Capture Toolbox for Enhanced Analysis of Intersegmental Coordination in Children with Cerebral Palsy and Typically Developing". _JOVE_ 206, e69604 (2025).
4. Nature Protocols Author Guidelines: https://www.nature.com/nprot/for-authors/protocols

---

## Mermaid Diagram of the Workflow

```mermaid
flowchart LR
    A["Stage I: Installation"] --> B["Stage II: Video Preprocessing"]
    B --> C["Stage III: 2D Pose Estimation"]
    C --> D["Stage IV: Calibration DLT"]
    D --> E["Stage V: 3D Reconstruction"]
    E --> F["Stage VI: Visualization and Export"]
```

---

_End of README_
